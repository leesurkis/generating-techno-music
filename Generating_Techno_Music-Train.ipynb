{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \n",
    "    \"\"\" This function calls all other functions and trains the LSTM\"\"\"\n",
    "    \n",
    "    notes = get_notes()\n",
    "\n",
    "    # get amount of pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "    model = create_network(network_input, n_vocab)\n",
    "\n",
    "    train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \n",
    "    \"\"\" Extracts all notes and chords from midi files in the ./midi_songs \n",
    "    directory and creates a file with all notes in string format\"\"\"\n",
    "    \n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(\"midi_songs/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \n",
    "    \"\"\" Prepare the sequences which are the inputs for the LSTM \"\"\"\n",
    "    \n",
    "    # sequence length should be changed after experimenting with different numbers\n",
    "    sequence_length = 30\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \n",
    "    \"\"\" Creates the structure of the neural network \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    \n",
    "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    # experiment with different epoch sizes and batch sizes\n",
    "    model.fit(network_input, network_output, epochs=30, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "68075/68075 [==============================] - 1048s 15ms/step - loss: 4.4730\n",
      "Epoch 2/30\n",
      "68075/68075 [==============================] - 991s 15ms/step - loss: 4.2867\n",
      "Epoch 3/30\n",
      "68075/68075 [==============================] - 956s 14ms/step - loss: 4.2145\n",
      "Epoch 4/30\n",
      "68075/68075 [==============================] - 957s 14ms/step - loss: 4.1138\n",
      "Epoch 5/30\n",
      "68075/68075 [==============================] - 1004s 15ms/step - loss: 3.8736\n",
      "Epoch 6/30\n",
      "68075/68075 [==============================] - 1034s 15ms/step - loss: 3.5210\n",
      "Epoch 7/30\n",
      "68075/68075 [==============================] - 1020s 15ms/step - loss: 3.1539\n",
      "Epoch 8/30\n",
      "68075/68075 [==============================] - 1052s 15ms/step - loss: 2.7338\n",
      "Epoch 9/30\n",
      "68075/68075 [==============================] - 1070s 16ms/step - loss: 2.3029\n",
      "Epoch 10/30\n",
      "68075/68075 [==============================] - 965s 14ms/step - loss: 1.9328\n",
      "Epoch 11/30\n",
      "68075/68075 [==============================] - 962s 14ms/step - loss: 1.6463\n",
      "Epoch 12/30\n",
      "68075/68075 [==============================] - 960s 14ms/step - loss: 1.4506\n",
      "Epoch 13/30\n",
      "68075/68075 [==============================] - 960s 14ms/step - loss: 1.2961\n",
      "Epoch 14/30\n",
      "68075/68075 [==============================] - 959s 14ms/step - loss: 1.1584\n",
      "Epoch 15/30\n",
      "68075/68075 [==============================] - 958s 14ms/step - loss: 1.0428\n",
      "Epoch 16/30\n",
      "68075/68075 [==============================] - 959s 14ms/step - loss: 0.9490\n",
      "Epoch 17/30\n",
      "68075/68075 [==============================] - 947s 14ms/step - loss: 0.8688\n",
      "Epoch 18/30\n",
      "68075/68075 [==============================] - 929s 14ms/step - loss: 0.8065\n",
      "Epoch 19/30\n",
      "68075/68075 [==============================] - 929s 14ms/step - loss: 0.7494\n",
      "Epoch 20/30\n",
      "68075/68075 [==============================] - 927s 14ms/step - loss: 0.7038\n",
      "Epoch 21/30\n",
      "68075/68075 [==============================] - 927s 14ms/step - loss: 0.6610\n",
      "Epoch 22/30\n",
      "68075/68075 [==============================] - 928s 14ms/step - loss: 0.6286\n",
      "Epoch 23/30\n",
      "68075/68075 [==============================] - 927s 14ms/step - loss: 0.6017\n",
      "Epoch 24/30\n",
      "68075/68075 [==============================] - 928s 14ms/step - loss: 0.5685\n",
      "Epoch 25/30\n",
      "68075/68075 [==============================] - 933s 14ms/step - loss: 0.5443\n",
      "Epoch 26/30\n",
      "68075/68075 [==============================] - 927s 14ms/step - loss: 0.5246\n",
      "Epoch 27/30\n",
      "68075/68075 [==============================] - 930s 14ms/step - loss: 0.5096\n",
      "Epoch 28/30\n",
      "68075/68075 [==============================] - 931s 14ms/step - loss: 0.4937\n",
      "Epoch 29/30\n",
      "68075/68075 [==============================] - 931s 14ms/step - loss: 0.4769\n",
      "Epoch 30/30\n",
      "68075/68075 [==============================] - 932s 14ms/step - loss: 0.4634\n"
     ]
    }
   ],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
